{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "726ab950-c0ea-4272-8d1c-5c4eb30aaeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 09:51:02.647639: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-28 09:51:02.827573: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /glade/u/apps/ch/opt/mpt_fmods/2.25/intel/19.1.1:/glade/u/apps/ch/opt/mpt/2.25/lib:/glade/u/apps/opt/intel/2020u1/compilers_and_libraries/linux/lib/intel64:/glade/u/apps/ch/os/usr/lib64:/glade/u/apps/ch/os/usr/lib:/glade/u/apps/ch/os/lib64:/glade/u/apps/ch/os/lib\n",
      "2022-09-28 09:51:02.827600: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-28 09:51:02.864650: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-28 09:51:09.175868: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /glade/u/apps/ch/opt/mpt_fmods/2.25/intel/19.1.1:/glade/u/apps/ch/opt/mpt/2.25/lib:/glade/u/apps/opt/intel/2020u1/compilers_and_libraries/linux/lib/intel64:/glade/u/apps/ch/os/usr/lib64:/glade/u/apps/ch/os/usr/lib:/glade/u/apps/ch/os/lib64:/glade/u/apps/ch/os/lib\n",
      "2022-09-28 09:51:09.176286: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /glade/u/apps/ch/opt/mpt_fmods/2.25/intel/19.1.1:/glade/u/apps/ch/opt/mpt/2.25/lib:/glade/u/apps/opt/intel/2020u1/compilers_and_libraries/linux/lib/intel64:/glade/u/apps/ch/os/usr/lib64:/glade/u/apps/ch/os/usr/lib:/glade/u/apps/ch/os/lib64:/glade/u/apps/ch/os/lib\n",
      "2022-09-28 09:51:09.176299: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import glob\n",
    "import pickle\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import product\n",
    "import joblib\n",
    "\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.feature as cf\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import matplotlib as mpl\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shapely.geometry as sgeom\n",
    "import xarray as xr\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import cdist\n",
    "from shapely import geometry\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, AveragePooling2D, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import LeakyReLU, ReLU\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import visualkeras\n",
    "\n",
    "import cluster_analysis, narm_analysis, som_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cf78a9-157b-4841-9624-dc1f1fe9764f",
   "metadata": {},
   "source": [
    "### Changes:\n",
    "\n",
    "#### Batch size: more stable weights\n",
    "#### Learning rate\n",
    "#### Scaling: (-1,1) (0,1)\n",
    "#### LeakyReLu vs. ReLu\n",
    "#### alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce31a6e-76db-4c05-a304-018bdb7c8fe4",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "515ac9a8-8310-4846-84e6-177a7c88b851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cold_indx(ds, mo_init=9, mo_end=2):\n",
    "    \"\"\"\n",
    "    Extract indices for cold season.\n",
    "    Grabbing Sept thru February init, for Oct thru March predictions.\n",
    "    \"\"\"\n",
    "    dt_array = pd.to_datetime(ds['date_range'])\n",
    "    # return dt_array\n",
    "    return xr.where((dt_array.month>=mo_init) | (dt_array.month<=mo_end), True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cedf0f2f-cd09-4dfe-8be3-a6f28aee1651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape,activation_function, num_classes=4,learning_rate = 0.001):\n",
    "    model = Sequential()\n",
    "    size_kernel = 3\n",
    "    model.add(Conv2D(64, kernel_size=(size_kernel, size_kernel),activation='linear',\n",
    "                     input_shape=input_shape,padding='same'))\n",
    "    model.add(activation_function())\n",
    "    model.add(AveragePooling2D((size_kernel, size_kernel),padding='same'))\n",
    "    model.add(Conv2D(128, (size_kernel, size_kernel), activation='linear',padding='same'))\n",
    "    model.add(activation_function())\n",
    "    model.add(AveragePooling2D(pool_size=(size_kernel, size_kernel),padding='same'))\n",
    "    model.add(Conv2D(256, (size_kernel, size_kernel), activation='linear',padding='same'))\n",
    "    model.add(activation_function())  \n",
    "    model.add(AveragePooling2D(pool_size=(size_kernel, size_kernel),padding='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='linear'))\n",
    "    model.add(activation_function())                  \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),\\\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6ab1a23-874b-40a9-a194-f89e660e027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train,X_test, y_test,batch_size = 64, epochs = 50,path_save=None,verbose=0):\n",
    "    callback = EarlyStopping(monitor='loss', patience=3)\n",
    "    history = model.fit(X_train, y_train, batch_size=batch_size,\\\n",
    "        epochs=epochs,verbose=verbose,validation_data=(X_test, y_test), callbacks=[callback])\n",
    "    if path_save:\n",
    "        model.save(path_save)    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c20e8a1-012d-4930-958e-122b38e6c8b6",
   "metadata": {},
   "source": [
    "# 1. Train only for week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a3fab8-1500-43d0-9c20-d6e991ba560b",
   "metadata": {},
   "source": [
    "## 1.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e0d7a97-1af8-4ab7-8974-9dc1fd8c0bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_models_cnn = '/glade/work/jhayron/Weather_Regimes/models/CNN/'\n",
    "path_files = '/glade/work/jhayron/Weather_Regimes/ERA5/'\n",
    "anoms_week_1 = xr.open_dataset(f'{path_files}era5_z500_anoms_mean_week1.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23406c6e-c0d3-4d66-9290-0df22b10c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "week = 2\n",
    "\n",
    "# Load weather regimes time series\n",
    "serie_wr_week = np.load(f'{path_files}Serie_WR_Week{week}.npy')\n",
    "\n",
    "# Make Y categorical\n",
    "serie_wr_categorical = to_categorical(serie_wr_week,num_classes=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f572ed-560e-4f23-af2f-9e3352bc4d5c",
   "metadata": {},
   "source": [
    "## 1.2 Which scaling is better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f0d546-62d1-48f3-a669-a8281e837a2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2.1 Min-Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee1c1d9c-82a1-400a-9546-d4944b2bd866",
   "metadata": {},
   "outputs": [],
   "source": [
    "Min = anoms_week_1.anom.min(dim='time')\n",
    "Max = anoms_week_1.anom.max(dim='time')\n",
    "\n",
    "scaled_x = (anoms_week_1.anom) / (Max - Min)\n",
    "#Reshape X\n",
    "scaled_x = scaled_x.data.reshape(-1, anoms_week_1.anom.shape[1],anoms_week_1.anom.shape[2], 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_x, serie_wr_categorical, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ed03177-0367-4d77-84bc-abbe8a192af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 7s 2s/step - loss: 1.3858 - accuracy: 0.2638 - val_loss: 1.3683 - val_accuracy: 0.3636\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.3618 - accuracy: 0.3509 - val_loss: 1.3251 - val_accuracy: 0.3545\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.3107 - accuracy: 0.3532 - val_loss: 1.3148 - val_accuracy: 0.3455\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.2797 - accuracy: 0.4060 - val_loss: 1.2472 - val_accuracy: 0.3909\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.2398 - accuracy: 0.4450 - val_loss: 1.2356 - val_accuracy: 0.3818\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.1922 - accuracy: 0.5161 - val_loss: 1.2382 - val_accuracy: 0.4182\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.1364 - accuracy: 0.4908 - val_loss: 1.2517 - val_accuracy: 0.4455\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.0941 - accuracy: 0.4885 - val_loss: 1.2095 - val_accuracy: 0.4636\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.0874 - accuracy: 0.4977 - val_loss: 1.2143 - val_accuracy: 0.4636\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 1.0275 - accuracy: 0.5459 - val_loss: 1.2596 - val_accuracy: 0.4545\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.9996 - accuracy: 0.5596 - val_loss: 1.2576 - val_accuracy: 0.4636\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.9618 - accuracy: 0.5826 - val_loss: 1.2531 - val_accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.9286 - accuracy: 0.6239 - val_loss: 1.3039 - val_accuracy: 0.4636\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.8787 - accuracy: 0.6468 - val_loss: 1.2783 - val_accuracy: 0.5182\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.8602 - accuracy: 0.6376 - val_loss: 1.3330 - val_accuracy: 0.4364\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.8089 - accuracy: 0.6560 - val_loss: 1.4495 - val_accuracy: 0.4909\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.8106 - accuracy: 0.6651 - val_loss: 1.3132 - val_accuracy: 0.5455\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.7094 - accuracy: 0.6972 - val_loss: 1.2855 - val_accuracy: 0.5636\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6833 - accuracy: 0.7156 - val_loss: 1.3707 - val_accuracy: 0.4727\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6403 - accuracy: 0.7339 - val_loss: 1.4614 - val_accuracy: 0.4727\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.6060 - accuracy: 0.7661 - val_loss: 1.6124 - val_accuracy: 0.5182\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.5011 - accuracy: 0.8165 - val_loss: 1.6231 - val_accuracy: 0.5000\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.4959 - accuracy: 0.8028 - val_loss: 1.7637 - val_accuracy: 0.5636\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.3712 - accuracy: 0.8647 - val_loss: 1.9027 - val_accuracy: 0.5000\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.3076 - accuracy: 0.8991 - val_loss: 1.8768 - val_accuracy: 0.5091\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.2743 - accuracy: 0.9014 - val_loss: 2.0652 - val_accuracy: 0.4909\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.1698 - accuracy: 0.9495 - val_loss: 2.3833 - val_accuracy: 0.4909\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.1394 - accuracy: 0.9564 - val_loss: 2.6006 - val_accuracy: 0.4636\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.0916 - accuracy: 0.9771 - val_loss: 2.9914 - val_accuracy: 0.5000\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.0514 - accuracy: 0.9908 - val_loss: 3.5141 - val_accuracy: 0.4636\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.0438 - accuracy: 0.9908 - val_loss: 3.9294 - val_accuracy: 0.5091\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.0389 - accuracy: 0.9908 - val_loss: 3.8820 - val_accuracy: 0.4636\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.0316 - accuracy: 0.9908 - val_loss: 4.3082 - val_accuracy: 0.5364\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.0279 - accuracy: 0.9931 - val_loss: 4.2768 - val_accuracy: 0.4636\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.0389 - accuracy: 0.9885 - val_loss: 4.7756 - val_accuracy: 0.5273\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.0611 - accuracy: 0.9817 - val_loss: 4.6066 - val_accuracy: 0.4727\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.0558 - accuracy: 0.9794 - val_loss: 4.3061 - val_accuracy: 0.5182\n"
     ]
    }
   ],
   "source": [
    "## Train and test model\n",
    "input_shape = X_train.shape[1:]\n",
    "model_temp = build_model(input_shape, ReLU, num_classes=4,learning_rate=0.01)\n",
    "model_temp = train_model(model_temp, X_train, y_train,X_test, y_test,\n",
    "    batch_size = 200, epochs = 50, path_save=f'{path_models_cnn}CNN_v0_week{week}_MinMaxScaling.h5',\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75a5ca28-2505-4db2-960d-69c3a1914322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 45ms/step - loss: 5.3233 - accuracy: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.323307991027832, 0.4000000059604645]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_temp.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42fd47e4-2066-4f89-b847-97aeca49bde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dc902f-50a9-4daf-abcc-5db5895ef7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5229f665-4184-46d9-bc1c-a4dcb490f387",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scale by standard deviation\n",
    "standard_deviation = anoms_week_1.anom.std(dim='time')\n",
    "scaled_x = anoms_week_1.anom / standard_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f7f71b-0f30-4b5c-8fbf-123df694b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape X\n",
    "scaled_x = scaled_x.data.reshape(-1, anoms_week_1.anom.shape[1],anoms_week_1.anom.shape[2], 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_x, serie_wr_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create empty model\n",
    "model = create_model()\n",
    "\n",
    "# Train\n",
    "callback = EarlyStopping(monitor='loss', patience=3)\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size,\\\n",
    "    epochs=epochs,verbose=0,validation_data=(X_test, y_test), callbacks=[callback])\n",
    "model.save(f'{path_models_cnn}CNN_v0_week{week}.h5')\n",
    "joblib.dump(model,f'{path_models_cnn}CNN_v0_week{week}.history')\n",
    "\n",
    "# Test\n",
    "y_test_predicted = model.predict(X_test)\n",
    "skill = 100 * len(np.where(np.argmax(y_test,axis=1) - np.argmax(y_test_predicted,axis=1) == 0)[0])/\\\n",
    "    len(np.argmax(y_test,axis=1))\n",
    "skills.append(skill)\n",
    "print(f'Skill week {week}: {np.round(skill,2)}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:weather_regimes]",
   "language": "python",
   "name": "conda-env-weather_regimes-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
