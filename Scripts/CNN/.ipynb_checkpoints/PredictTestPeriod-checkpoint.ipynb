{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f074931-56b1-4d97-abf2-dc600525ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import pickle\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import product\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.feature as cf\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import matplotlib as mpl\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# np.random.seed(42)\n",
    "import pandas as pd\n",
    "import shapely.geometry as sgeom\n",
    "import xarray as xr\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import cdist\n",
    "from shapely import geometry\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# import cluster_analysis, narm_analysis, som_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73da05ac-ef73-41f3-9efd-7f1743760936",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aee4bc-9be4-458e-b3c4-f637b16a7016",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Weather regimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a40047a6-fca9-4719-9b9c-0d9c0b814f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "week1_wr = pd.read_csv('/glade/work/jhayron/Weather_Regimes/weekly_wr/week1_wr_v3.csv',\\\n",
    "                      index_col = 0, parse_dates = True)\n",
    "week2_wr = pd.read_csv('/glade/work/jhayron/Weather_Regimes/weekly_wr/week2_wr_v3.csv',\\\n",
    "                      index_col = 0, parse_dates = True)\n",
    "week3_wr = pd.read_csv('/glade/work/jhayron/Weather_Regimes/weekly_wr/week3_wr_v3.csv',\\\n",
    "                      index_col = 0, parse_dates = True)\n",
    "week4_wr = pd.read_csv('/glade/work/jhayron/Weather_Regimes/weekly_wr/week4_wr_v3.csv',\\\n",
    "                      index_col = 0, parse_dates = True)\n",
    "week5_wr = pd.read_csv('/glade/work/jhayron/Weather_Regimes/weekly_wr/week5_wr_v3.csv',\\\n",
    "                      index_col = 0, parse_dates = True)\n",
    "week6_wr = pd.read_csv('/glade/work/jhayron/Weather_Regimes/weekly_wr/week6_wr_v3.csv',\\\n",
    "                      index_col = 0, parse_dates = True)\n",
    "week7_wr = pd.read_csv('/glade/work/jhayron/Weather_Regimes/weekly_wr/week7_wr_v3.csv',\\\n",
    "                      index_col = 0, parse_dates = True)\n",
    "week8_wr = pd.read_csv('/glade/work/jhayron/Weather_Regimes/weekly_wr/week8_wr_v3.csv',\\\n",
    "                      index_col = 0, parse_dates = True)\n",
    "week9_wr = pd.read_csv('/glade/work/jhayron/Weather_Regimes/weekly_wr/week9_wr_v3.csv',\\\n",
    "                      index_col = 0, parse_dates = True)\n",
    "\n",
    "df_wr = pd.concat([week1_wr,week2_wr,week3_wr,week4_wr,week5_wr,week6_wr,week7_wr,week8_wr,week9_wr],axis=1)\n",
    "df_wr.columns = ['week1','week2','week3','week4','week5','week6','week7','week8','week9']\n",
    "\n",
    "df_wr_2 = pd.read_csv('/glade/work/jhayron/Weather_Regimes/weekly_wr/weekly_wr_mean_geop_v3.csv',\n",
    "                     index_col=0,parse_dates=True)\n",
    "\n",
    "df_wr_2 = df_wr_2.dropna()\n",
    "df_wr = df_wr.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e404c3d-4968-4204-b0ed-fe95bfb6d6ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beb3164d-10c0-4073-ac3a-4f8d4634b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['z500','olr', 'sst', 'u10', 'sm_region', 'st_region']\n",
    "name_var = ['z500','olr', 'sst', 'u10', 'sm', 'st']\n",
    "units = ['m2/s2','J/m2','K','m/s','m3/m3','K']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caa0c0e0-15fa-47a6-8117-d6f2a8313107",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dic_vars = {}\n",
    "for var_short, variable,unit in zip(name_var,variables,units):\n",
    "# for var_short, variable,unit in zip(['sst'],['sst'],['K']):\n",
    "    path_w_anoms = '/glade/work/jhayron/Weather_Regimes/weekly_anomalies/'\n",
    "    week1_anoms = xr.open_dataset(f'{path_w_anoms}week1_{variable}_anoms_v3.nc')\n",
    "    # week1_anoms = week1_anoms.sel(time=df_wr_2.index)\n",
    "    if variable=='z500':\n",
    "        week1_anoms = week1_anoms.where(week1_anoms.lat>-30,drop=True)\n",
    "    # week1_anoms = week1_anoms.sel(time=df_wr.index)\n",
    "    week1_anoms = week1_anoms.sel(time=df_wr_2.index)\n",
    "    dic_vars[variable] = week1_anoms\n",
    "    \n",
    "    ##########PLOT#####################\n",
    "#     fig = plt.figure(figsize=(9,7))\n",
    "#     ax = fig.add_subplot(111,projection=ccrs.PlateCarree(central_longitude=-90+360))\n",
    "    \n",
    "#     #     vmax = np.round(np.percentile(abs(week1_anoms[f'{var_short}_anomalies'].values[0]),100),0)\n",
    "#     #     vmin = -np.round(np.percentile(abs(week1_anoms[f'{var_short}_anomalies'].values[0]),100),0)\n",
    "    \n",
    "#     vmax = np.round(np.percentile(abs(week1_anoms[f'{var_short}_anomalies'].values[0]),100),0)\n",
    "#     vmin = -np.round(np.percentile(abs(week1_anoms[f'{var_short}_anomalies'].values[0]),100),0)\n",
    "#     # print(vmax,vmin)\n",
    "#     cs = plt.pcolormesh(week1_anoms.lon,week1_anoms.lat,\\\n",
    "#         week1_anoms[f'{var_short}_anomalies'].values[0],cmap='seismic',\n",
    "#         transform=ccrs.PlateCarree(),vmin=vmin,vmax=vmax)\n",
    "#     ax.coastlines(resolution='110m', color='k', linewidth=0.75, zorder=10)\n",
    "#     ax.margins(x=0, y=0)\n",
    "\n",
    "#     # ax.set_extent([-179, 179, 10, 90], crs=ccrs.PlateCarree())\n",
    "#     if variable!='st':\n",
    "#         plt.title(variable.upper().replace('_','-'))\n",
    "#     else:\n",
    "#         plt.title(variable.upper().replace('_','-').replace('ST','TS'))\n",
    "#     if 'region' in variable:\n",
    "#         cbar_ax = fig.add_axes([0.25, 0.19, 0.5, 0.0175])\n",
    "#     else:\n",
    "#         cbar_ax = fig.add_axes([0.25, 0.3, 0.5, 0.0175])\n",
    "#     # ticks_1 = [-80, -40, 0, 40, 80]\n",
    "#     cbar = fig.colorbar(cs, cax=cbar_ax,\n",
    "#                         orientation='horizontal', extend='both')\n",
    "#     cbar.ax.tick_params(labelsize=14)\n",
    "#     cbar.set_label(unit, fontsize=14)\n",
    "#     plt.savefig(f'/glade/u/home/jhayron/WeatherRegimes/Figures/MapsVariables/{variable}_anomalies_v2.png',bbox_inches='tight')\n",
    "#     plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b09832-3831-4dc7-aeb2-6b7b65e854e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddc9b5e7-a5ad-44d1-8c4e-34456f6484ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, AveragePooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import ReLU\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "# import visualkeras\n",
    "# import tensorflow as tf\n",
    "\n",
    "# ## GLOBAL SEED ##    \n",
    "# np.random.seed(42)\n",
    "# tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472b482e-df08-4a1a-8d3d-39e9d75a8717",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2aafbf6-aa12-479e-bc0e-f6896f991198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(activation_conv = ReLU()):\n",
    "    num_classes = 4\n",
    "    # alpha=0.01\n",
    "    ks = 3\n",
    "    ps = 5\n",
    "    nfilters=64\n",
    "    padding_type = 'valid'\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(nfilters, kernel_size=(ks, ks),activation=activation_conv,\n",
    "        input_shape=X_train.shape[1:],padding=padding_type))\n",
    "    model.add(AveragePooling2D((ps, ps),padding=padding_type))\n",
    "    \n",
    "    model.add(Conv2D(nfilters*2, (ks, ks), activation=activation_conv,padding=padding_type))\n",
    "    model.add(AveragePooling2D(pool_size=(ps, ps),padding=padding_type))\n",
    "    \n",
    "    # model.add(Conv2D(nfilters*3, (ks, ks), activation=activation_conv,padding=padding_type))\n",
    "    # model.add(AveragePooling2D(pool_size=(ps, ps),padding=padding_type))\n",
    "    \n",
    "    # model.add(Conv2D(128, (ks, ks), activation=activation_conv,padding='same'))\n",
    "    # model.add(AveragePooling2D(pool_size=(ks, ks),padding='same'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation=activation_conv))\n",
    "    model.add(Dense(64, activation=activation_conv))\n",
    "    model.add(Dense(64, activation=activation_conv))\n",
    "    # model.add(Dense(nfilters, activation=activation_conv))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "        optimizer=keras.optimizers.Adam(lr=0.0001),metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5daa2338-fc25-4638-b503-36e7da6b6ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_models = '/glade/work/jhayron/Weather_Regimes/models/CNN/weights_variables_v3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b1c24ab-06d0-42c5-91a2-fa4a70e28111",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************************\n",
      "z500\n",
      "********************************************************************************************\n",
      "week2\n",
      "week3\n",
      "week4\n",
      "week5\n",
      "week6\n",
      "week7\n",
      "week8\n",
      "week9\n",
      "********************************************************************************************\n",
      "olr\n",
      "********************************************************************************************\n",
      "week2\n",
      "week3\n",
      "week4\n",
      "week5\n",
      "week6\n",
      "week7\n",
      "week8\n",
      "week9\n",
      "********************************************************************************************\n",
      "sst\n",
      "********************************************************************************************\n",
      "week2\n",
      "week3\n",
      "week4\n",
      "week5\n",
      "week6\n",
      "week7\n",
      "week8\n",
      "week9\n",
      "********************************************************************************************\n",
      "u10\n",
      "********************************************************************************************\n",
      "week2\n",
      "week3\n",
      "week4\n",
      "week5\n",
      "week6\n",
      "week7\n",
      "week8\n",
      "week9\n",
      "********************************************************************************************\n",
      "sm_region\n",
      "********************************************************************************************\n",
      "week2\n",
      "week3\n",
      "week4\n",
      "week5\n",
      "week6\n",
      "week7\n",
      "week8\n",
      "week9\n",
      "********************************************************************************************\n",
      "st_region\n",
      "********************************************************************************************\n",
      "week2\n",
      "week3\n",
      "week4\n",
      "week5\n",
      "week6\n",
      "week7\n",
      "week8\n",
      "week9\n"
     ]
    }
   ],
   "source": [
    "dic_results = {}\n",
    "dic_probability = {}\n",
    "\n",
    "for var_short, variable in zip(name_var,variables):\n",
    "    print('********************************************************************************************')\n",
    "    print(variable)\n",
    "    print('********************************************************************************************')\n",
    "    loss_weeks_model = []\n",
    "    loss_weeks_persistence = []\n",
    "    acc_weeks_model = []\n",
    "    acc_weeks_persistence = []\n",
    "    \n",
    "    df_results_persistence = pd.DataFrame()\n",
    "    df_results = pd.DataFrame()\n",
    "    df_probability = pd.DataFrame()\n",
    "    for week in ['week2','week3','week4','week5','week6','week7','week8','week9']:\n",
    "        print(week)\n",
    "        #### ORGANIZE DATA ####\n",
    "        week_output_wr = df_wr_2[week].values.astype(int)\n",
    "        # Make Y categorical\n",
    "        serie_wr_categorical = to_categorical(week_output_wr,num_classes=4)\n",
    "        \n",
    "        week1_anoms = copy.deepcopy(dic_vars[variable])\n",
    "        \n",
    "        # # Scale by min-max\n",
    "        where = np.where(pd.to_datetime(week1_anoms.time.values).year<=2010)[0]\n",
    "        Min = week1_anoms.isel(time=where)[f'{var_short}_anomalies'].min(dim='time')\n",
    "        Max = week1_anoms.isel(time=where)[f'{var_short}_anomalies'].max(dim='time')\n",
    "        scaled_x = (week1_anoms[f'{var_short}_anomalies']) / (Max - Min)\n",
    "\n",
    "        indices = np.arange(len(serie_wr_categorical))\n",
    "        #Reshape X\n",
    "        scaled_x = scaled_x.data.reshape(-1, scaled_x.shape[1],scaled_x.shape[2], 1)\n",
    "        scaled_x[np.isfinite(scaled_x)==False]=0\n",
    "        \n",
    "        indices_train = np.where(df_wr_2.week2.index.year<=2001)[0]\n",
    "        indices_val = np.where((df_wr_2.week2.index.year>2001)&(df_wr_2.week2.index.year<=2010))[0]\n",
    "        indices_test = np.where(df_wr_2.week2.index.year>2010)[0]\n",
    "\n",
    "        X_test = scaled_x[indices_test]\n",
    "        y_test = serie_wr_categorical[indices_test]\n",
    "\n",
    "        X_train = scaled_x[indices_train]\n",
    "        y_train = serie_wr_categorical[indices_train]\n",
    "\n",
    "        X_val = scaled_x[indices_val]\n",
    "        y_val = serie_wr_categorical[indices_val]\n",
    "\n",
    "        wr_persistence = df_wr_2.week1.values.astype(int)[indices_test]\n",
    "        serie_wr_persistence_categorical = to_categorical(wr_persistence)\n",
    "        \n",
    "        df_results_persistence[week] = wr_persistence\n",
    "        #### Predict ####\n",
    "\n",
    "        keras.backend.clear_session()\n",
    "        filepath = f'{path_models}{variable}/model_{week}_v3.h5'\n",
    "        model = create_model()\n",
    "        model.load_weights(filepath)\n",
    "        results = model.predict(X_test)\n",
    "        prob_temp = results.max(axis=1)\n",
    "        result_temp = results.argmax(axis=1)\n",
    "        \n",
    "        df_results[week] = result_temp\n",
    "        df_probability[week] = prob_temp\n",
    "        df_results_persistence[week] = wr_persistence\n",
    "    df_results.index = df_wr_2.iloc[indices_test].index\n",
    "    df_probability.index = df_wr_2.iloc[indices_test].index\n",
    "    df_results_persistence.index = df_wr_2.iloc[indices_test].index\n",
    "    dic_results[variable] = df_results\n",
    "    dic_probability[variable] = df_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "46ad9258-865e-4e10-ac0d-25f800f154dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/glade/work/jhayron/Weather_Regimes/models_results/CNN_v3/dic_results.npy',dic_results)\n",
    "np.save('/glade/work/jhayron/Weather_Regimes/models_results/CNN_v3/dic_probability.npy',dic_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8742eb53-5b46-4c08-add1-3167013a8efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_persistence.to_csv('/glade/work/jhayron/Weather_Regimes/models_results/CNN_v3/dic_probability.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL-3.7.9",
   "language": "python",
   "name": "npl-3.7.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
