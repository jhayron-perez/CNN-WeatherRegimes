{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f074931-56b1-4d97-abf2-dc600525ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import pickle\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import product\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.feature as cf\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import matplotlib as mpl\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# np.random.seed(42)\n",
    "import pandas as pd\n",
    "import shapely.geometry as sgeom\n",
    "import xarray as xr\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import cdist\n",
    "from shapely import geometry\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# import cluster_analysis, narm_analysis, som_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9711381b-062d-4ac9-a8b5-220897089856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-01-04 19:07:52.196456: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.integration import TFKerasPruningCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73da05ac-ef73-41f3-9efd-7f1743760936",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aee4bc-9be4-458e-b3c4-f637b16a7016",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Weather regimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a40047a6-fca9-4719-9b9c-0d9c0b814f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "week1_wr = pd.read_csv('/glade/work/jhayron/Weather_Regimes/weekly_wr/week1_wr_v3.csv',\\\n",
    "                      index_col = 0, parse_dates = True)\n",
    "week2_wr = pd.read_csv('/glade/work/jhayron/Weather_Regimes/weekly_wr/week2_wr_v3.csv',\\\n",
    "                      index_col = 0, parse_dates = True)\n",
    "week3_wr = pd.read_csv('/glade/work/jhayron/Weather_Regimes/weekly_wr/week3_wr_v3.csv',\\\n",
    "                      index_col = 0, parse_dates = True)\n",
    "week4_wr = pd.read_csv('/glade/work/jhayron/Weather_Regimes/weekly_wr/week4_wr_v3.csv',\\\n",
    "                      index_col = 0, parse_dates = True)\n",
    "week5_wr = pd.read_csv('/glade/work/jhayron/Weather_Regimes/weekly_wr/week5_wr_v3.csv',\\\n",
    "                      index_col = 0, parse_dates = True)\n",
    "week6_wr = pd.read_csv('/glade/work/jhayron/Weather_Regimes/weekly_wr/week6_wr_v3.csv',\\\n",
    "                      index_col = 0, parse_dates = True)\n",
    "week7_wr = pd.read_csv('/glade/work/jhayron/Weather_Regimes/weekly_wr/week7_wr_v3.csv',\\\n",
    "                      index_col = 0, parse_dates = True)\n",
    "week8_wr = pd.read_csv('/glade/work/jhayron/Weather_Regimes/weekly_wr/week8_wr_v3.csv',\\\n",
    "                      index_col = 0, parse_dates = True)\n",
    "week9_wr = pd.read_csv('/glade/work/jhayron/Weather_Regimes/weekly_wr/week9_wr_v3.csv',\\\n",
    "                      index_col = 0, parse_dates = True)\n",
    "\n",
    "df_wr = pd.concat([week1_wr,week2_wr,week3_wr,week4_wr,week5_wr,week6_wr,week7_wr,week8_wr,week9_wr],axis=1)\n",
    "df_wr.columns = ['week1','week2','week3','week4','week5','week6','week7','week8','week9']\n",
    "\n",
    "df_wr_2 = pd.read_csv('/glade/work/jhayron/Weather_Regimes/weekly_wr/weekly_wr_mean_geop_v3.csv',\n",
    "                     index_col=0,parse_dates=True)\n",
    "\n",
    "df_wr_2 = df_wr_2.dropna()\n",
    "df_wr = df_wr.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e404c3d-4968-4204-b0ed-fe95bfb6d6ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beb3164d-10c0-4073-ac3a-4f8d4634b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['z500']\n",
    "name_var = ['z500']\n",
    "units = ['m2/s2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caa0c0e0-15fa-47a6-8117-d6f2a8313107",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dic_vars = {}\n",
    "for var_short, variable,unit in zip(name_var,variables,units):\n",
    "# for var_short, variable,unit in zip(['sst'],['sst'],['K']):\n",
    "    path_w_anoms = '/glade/work/jhayron/Weather_Regimes/weekly_anomalies/'\n",
    "    week1_anoms = xr.open_dataset(f'{path_w_anoms}week1_{variable}_anoms_v3.nc')\n",
    "    # week1_anoms = week1_anoms.sel(time=df_wr_2.index)\n",
    "    if variable=='z500':\n",
    "        week1_anoms = week1_anoms.where(week1_anoms.lat>-30,drop=True)\n",
    "    # week1_anoms = week1_anoms.sel(time=df_wr.index)\n",
    "    week1_anoms = week1_anoms.sel(time=df_wr_2.index)\n",
    "    dic_vars[variable] = week1_anoms\n",
    "    \n",
    "    ##########PLOT#####################\n",
    "#     fig = plt.figure(figsize=(9,7))\n",
    "#     ax = fig.add_subplot(111,projection=ccrs.PlateCarree(central_longitude=-90+360))\n",
    "    \n",
    "#     #     vmax = np.round(np.percentile(abs(week1_anoms[f'{var_short}_anomalies'].values[0]),100),0)\n",
    "#     #     vmin = -np.round(np.percentile(abs(week1_anoms[f'{var_short}_anomalies'].values[0]),100),0)\n",
    "    \n",
    "#     vmax = np.round(np.percentile(abs(week1_anoms[f'{var_short}_anomalies'].values[0]),100),0)\n",
    "#     vmin = -np.round(np.percentile(abs(week1_anoms[f'{var_short}_anomalies'].values[0]),100),0)\n",
    "#     # print(vmax,vmin)\n",
    "#     cs = plt.pcolormesh(week1_anoms.lon,week1_anoms.lat,\\\n",
    "#         week1_anoms[f'{var_short}_anomalies'].values[0],cmap='seismic',\n",
    "#         transform=ccrs.PlateCarree(),vmin=vmin,vmax=vmax)\n",
    "#     ax.coastlines(resolution='110m', color='k', linewidth=0.75, zorder=10)\n",
    "#     ax.margins(x=0, y=0)\n",
    "\n",
    "#     # ax.set_extent([-179, 179, 10, 90], crs=ccrs.PlateCarree())\n",
    "#     if variable!='st':\n",
    "#         plt.title(variable.upper().replace('_','-'))\n",
    "#     else:\n",
    "#         plt.title(variable.upper().replace('_','-').replace('ST','TS'))\n",
    "#     if 'region' in variable:\n",
    "#         cbar_ax = fig.add_axes([0.25, 0.19, 0.5, 0.0175])\n",
    "#     else:\n",
    "#         cbar_ax = fig.add_axes([0.25, 0.3, 0.5, 0.0175])\n",
    "#     # ticks_1 = [-80, -40, 0, 40, 80]\n",
    "#     cbar = fig.colorbar(cs, cax=cbar_ax,\n",
    "#                         orientation='horizontal', extend='both')\n",
    "#     cbar.ax.tick_params(labelsize=14)\n",
    "#     cbar.set_label(unit, fontsize=14)\n",
    "#     plt.savefig(f'/glade/u/home/jhayron/WeatherRegimes/Figures/MapsVariables/{variable}_anomalies_v2.png',bbox_inches='tight')\n",
    "#     plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b09832-3831-4dc7-aeb2-6b7b65e854e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddc9b5e7-a5ad-44d1-8c4e-34456f6484ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, AveragePooling2D, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import ReLU\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "# import visualkeras\n",
    "# import tensorflow as tf\n",
    "\n",
    "# ## GLOBAL SEED ##    \n",
    "# np.random.seed(42)\n",
    "# tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472b482e-df08-4a1a-8d3d-39e9d75a8717",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2aafbf6-aa12-479e-bc0e-f6896f991198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(ks,ps,st,do,md,nfilters,lr,activation_conv = LeakyReLU()):\n",
    "    num_classes = 4\n",
    "    # alpha=0.01\n",
    "    # ks = 3\n",
    "    # ps = 5\n",
    "    # st = 3\n",
    "    # do = 0.4\n",
    "    # md = 16\n",
    "    # nfilters=32\n",
    "    padding_type = 'same'\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(nfilters, kernel_size=(ks, ks),activation=activation_conv,\n",
    "        input_shape=X_train.shape[1:],padding=padding_type))\n",
    "    model.add(AveragePooling2D((ps, ps),padding=padding_type,strides=st))\n",
    "    model.add(Dropout(do))\n",
    "    model.add(Conv2D(nfilters*2, (ks, ks), activation=activation_conv,padding=padding_type))\n",
    "    model.add(AveragePooling2D((ps, ps),padding=padding_type,strides=st))\n",
    "    model.add(Dropout(do))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes*md*md, activation=activation_conv))\n",
    "    model.add(Dropout(do))\n",
    "    model.add(Dense(num_classes*md, activation=activation_conv))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "        optimizer=keras.optimizers.Adam(lr=lr),metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5daa2338-fc25-4638-b503-36e7da6b6ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_models = '/glade/work/jhayron/Weather_Regimes/models/CNN/weights_variables_v6/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b1c24ab-06d0-42c5-91a2-fa4a70e28111",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************************\n",
      "z500\n",
      "********************************************************************************************\n",
      "week1\n",
      "{'ks': 11, 'ps': 5, 'st': 2, 'do': 0.2, 'md': 16, 'nfilters': 16, 'lr': 1e-05, 'bs': 16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 19:08:34.994248: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-01-04 19:08:35.055684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-01-04 19:08:35.562134: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-01-04 19:08:35.562241: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (crhtc46): /proc/driver/nvidia/version does not exist\n",
      "2023-01-04 19:08:35.574853: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-04 19:08:35.575072: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-01-04 19:08:40.138777: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-01-04 19:08:40.142388: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "week2\n",
      "{'ks': 13, 'ps': 9, 'st': 2, 'do': 0.5, 'md': 32, 'nfilters': 32, 'lr': 1e-05, 'bs': 64}\n",
      "week3\n",
      "{'ks': 5, 'ps': 13, 'st': 4, 'do': 0.3, 'md': 2, 'nfilters': 32, 'lr': 0.0001, 'bs': 16}\n"
     ]
    }
   ],
   "source": [
    "dic_results = {}\n",
    "dic_probability = {}\n",
    "\n",
    "for var_short, variable in zip(name_var,variables):\n",
    "    print('********************************************************************************************')\n",
    "    print(variable)\n",
    "    print('********************************************************************************************')\n",
    "    loss_weeks_model = []\n",
    "    loss_weeks_persistence = []\n",
    "    acc_weeks_model = []\n",
    "    acc_weeks_persistence = []\n",
    "    \n",
    "    df_results_persistence = pd.DataFrame()\n",
    "    df_results = pd.DataFrame()\n",
    "    df_probability = pd.DataFrame()\n",
    "    for week in ['week1','week2','week3']:\n",
    "        print(week)\n",
    "        #### ORGANIZE DATA ####\n",
    "        week_output_wr = df_wr_2[week].values.astype(int)\n",
    "        # Make Y categorical\n",
    "        serie_wr_categorical = to_categorical(week_output_wr,num_classes=4)\n",
    "        \n",
    "        week1_anoms = copy.deepcopy(dic_vars[variable])\n",
    "        \n",
    "        # # Scale by min-max\n",
    "        where = np.where(pd.to_datetime(week1_anoms.time.values).year<=2010)[0]\n",
    "        Min = week1_anoms.isel(time=where)[f'{var_short}_anomalies'].min(dim='time')\n",
    "        Max = week1_anoms.isel(time=where)[f'{var_short}_anomalies'].max(dim='time')\n",
    "        scaled_x = (week1_anoms[f'{var_short}_anomalies']) / (Max - Min)\n",
    "\n",
    "        indices = np.arange(len(serie_wr_categorical))\n",
    "        #Reshape X\n",
    "        scaled_x = scaled_x.data.reshape(-1, scaled_x.shape[1],scaled_x.shape[2], 1)\n",
    "        scaled_x[np.isfinite(scaled_x)==False]=0\n",
    "        \n",
    "        indices_train = np.where(df_wr_2.week2.index.year<=2001)[0]\n",
    "        indices_val = np.where((df_wr_2.week2.index.year>2001)&(df_wr_2.week2.index.year<=2010))[0]\n",
    "        indices_test = np.where(df_wr_2.week2.index.year>2010)[0]\n",
    "\n",
    "        X_test = scaled_x[indices_test]\n",
    "        y_test = serie_wr_categorical[indices_test]\n",
    "\n",
    "        X_train = scaled_x[indices_train]\n",
    "        y_train = serie_wr_categorical[indices_train]\n",
    "\n",
    "        X_val = scaled_x[indices_val]\n",
    "        y_val = serie_wr_categorical[indices_val]\n",
    "\n",
    "        wr_persistence = df_wr_2.week1.values.astype(int)[indices_test]\n",
    "        serie_wr_persistence_categorical = to_categorical(wr_persistence)\n",
    "        \n",
    "        df_results_persistence[week] = wr_persistence\n",
    "        \n",
    "        \n",
    "        ## TRAIN\n",
    "        results_directory = f'/glade/work/jhayron/Weather_Regimes/models/CNN/results_optuna/{week}/'\n",
    "        study_optuna = joblib.load(results_directory + 'optuna_study.pkl')\n",
    "        dict_params = study_optuna.best_params\n",
    "        print(dict_params)\n",
    "        keras.backend.clear_session()\n",
    "        model = create_model(dict_params['ks'],\n",
    "                             dict_params['ps'],\n",
    "                             dict_params['st'],\n",
    "                             dict_params['do'],\n",
    "                             dict_params['md'],\n",
    "                             dict_params['nfilters'],\n",
    "                             dict_params['lr'],\n",
    "                            )\n",
    "\n",
    "        earlystop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "        try:\n",
    "            os.mkdir(f'{path_models}{variable}')\n",
    "        except: pass\n",
    "        filepath = f'{path_models}{variable}/model_{week}_v6.h5'\n",
    "\n",
    "        #### EVAL ####\n",
    "\n",
    "        model.load_weights(filepath)\n",
    "        results = model.predict(X_test)\n",
    "        prob_temp = results.max(axis=1)\n",
    "        result_temp = results.argmax(axis=1)\n",
    "        \n",
    "        df_results[week] = result_temp\n",
    "        df_probability[week] = prob_temp\n",
    "        df_results_persistence[week] = wr_persistence\n",
    "    df_results.index = df_wr_2.iloc[indices_test].index\n",
    "    df_probability.index = df_wr_2.iloc[indices_test].index\n",
    "    df_results_persistence.index = df_wr_2.iloc[indices_test].index\n",
    "    dic_results[variable] = df_results\n",
    "    dic_probability[variable] = df_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46ad9258-865e-4e10-ac0d-25f800f154dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/glade/work/jhayron/Weather_Regimes/models_results/CNN_v6/dic_results.npy',dic_results)\n",
    "np.save('/glade/work/jhayron/Weather_Regimes/models_results/CNN_v6/dic_probability.npy',dic_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8742eb53-5b46-4c08-add1-3167013a8efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_persistence.to_csv('/glade/work/jhayron/Weather_Regimes/models_results/CNN_v6/dic_probability_persistence.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba821de-5ad4-4b37-8142-60f317e97403",
   "metadata": {},
   "source": [
    "# Plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcb8915a-81b6-4194-b40f-2b4787388595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import visualkeras\n",
    "# # visualkeras.layered_view(model, legend=True) # without custom font\n",
    "# from PIL import ImageFont\n",
    "# # font = ImageFont.truetype(\"arial.ttf\", 12)\n",
    "# visualkeras.layered_view(model, legend=True,draw_volume=False) # selected font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3091bd9f-2f43-4abd-bb66-916b0c867363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "path_figs = '/glade/u/home/jhayron/WeatherRegimes/Figures/'\n",
    "plot_model(model, to_file=f'{path_figs}CNNShape_v6.png', show_shapes=False, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4291628c-baf2-4966-8642-3cfbb044f740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 120, 360, 32)      832       \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 30, 90, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30, 90, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 90, 64)        51264     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 8, 23, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 23, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 11776)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                188432    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 240,700\n",
      "Trainable params: 240,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6afa3510-05a4-4cb4-852d-de9049abd641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(555, 120, 360, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cnn_wr]",
   "language": "python",
   "name": "conda-env-cnn_wr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
